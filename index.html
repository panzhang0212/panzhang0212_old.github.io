<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Pan Zhang</title>
  
  <meta name="author" content="Pan Zhang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Pan Zhang</name>
              </p>
              <p style="text-align:center">
                <a href="mailto:t-pazhan@microsoft.com">Email</a> &nbsp; &nbsp;&nbsp;&nbsp;
                <a href="https://github.com/panzhang0212">Github</a> 
              </p>
              <p>I am a <a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-asia/">Microsoft Research Asia(MSRA)</a> Joint PhD student from <a href="https://www.ustc.edu.cn/">University of Science and Technology of China(USTC)</a>. 
                I am working in <a href="https://www.microsoft.com/en-us/research/group/visual-computing/">Visual Computing Group</a> in MSRA as a research intern, 
                under the supervision of Researcher <a href="https://www.microsoft.com/en-us/research/people/zhanbo/">Bo Zhang</a>, Principal Research Manager <a href="https://www.microsoft.com/en-us/research/people/doch/">Dong Chen</a>, 
                and <a href="https://www.microsoft.com/en-us/research/people/bainguo/"> Prof. Baining Guo</a>.
              </p>
              <p>
                I received B.S. from Department of Electronic Engineering and Information Science of USTC in 2017.
              </p>
            </td>
            <td style="padding:15% 7% 7% 7%;width:40%;max-width:40%">
              <a href="images/PanZhang.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/PanZhang.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

        <tr></tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                <img src='images/CocoNet_teaser.png' style="width:100%;max-width:100%; position: absolute;top: -5%">
                </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Cross-domain Correspondence Learning for Exemplar-based Image Translation</papertitle>
                <br>
                <strong>Pan Zhang</strong>, Bo Zhang, Dong Chen, Lu Yuan, Fang Wen
                <br>
                <em>2020 IEEE Conference on Computer Vision and Pattern Recognition</em>, CVPR 2020,
				<strong>Oral Presentation</strong>
                <br>
				<a href="https://panzhang0212.github.io/CoCosNet/">[Project]</a>
                <a href="https://arxiv.org/abs/2004.05571">[PDF]</a>
                <a >[Code coming soon]</a>
				<a href="https://www.dropbox.com/s/g7dezxm2mhw6gqo/CoCosNet%20slides.pptx?dl=0">[Slides]</a>
				<a href="https://youtu.be/BdopAApRSgo">[Youtube]</a>
				<a href="images/cocosnet_bib.txt">[BibTeX]</a>
                <br>
                <p>We present a general framework for exemplar-based image translation by jointly learning the cross-domain correspondence and the image translation, where
                both tasks facilitate each other and thus can be learned with weak supervision.</p>
            </td>
        </tr>
          
        <tr></tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one" >
                    <img src='images/OldPhotos_teaser.png' style="width:100%;max-width:100%; position: absolute;top: -5%">
                </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Bringing Old Photos Back to Life</papertitle>
                <br>
                Ziyu Wan, Bo Zhang, Dongdong Chen, <strong>Pan Zhang</strong>, Dong Chen, Jing Liao, Fang Wen
                <br>
                <em>2020 IEEE Conference on Computer Vision and Pattern Recognition</em>, CVPR 2020, 
				<strong>Oral Presentation</strong>
                <br>
				<a href="http://raywzy.com/Old_Photo/">[Project]</a>
                <a href="https://arxiv.org/abs/2004.09484">[PDF]</a>
                <a >[Code coming soon]</a>
				<a href="images/oldphoto_bib.txt">[BibTeX]</a>
                <br>
                <p>We propose to restore old photos that suffer from severe multiple degradations through a deep learning approach, 
                    and a novel triplet domain translation network by leveraging real photos along with massive synthetic image pairs.</p>
            </td>
        </tr>

      </td>
    </tr>
  </table>
</body>

</html>